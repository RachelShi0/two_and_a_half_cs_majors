{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# import the module from the file\n",
    "from moving_average import moving_avg_np_array\n",
    "from preprocessing import minmax_scaler, piecewise_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(\"./\", search_parent_directories=True)\n",
    "homedir = repo.working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import daily covid cases per county\n",
    "counties_df = pd.read_csv(f\"{homedir}/data/us/covid/nyt_us_counties_daily.csv\")\n",
    "counties_df = counties_df[counties_df['state'].notna()] #drop rows where state is NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode states and add column to dataframe\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "states = np.array(counties_df['state']).reshape(-1, 1)\n",
    "one_hot_encoder.fit(states)\n",
    "states_encoded = one_hot_encoder.transform(states).toarray()\n",
    "\n",
    "counties_df['states_encoded'] = states_encoded.tolist() #add column to dataframe\n",
    "\n",
    "#convert date to datetime format\n",
    "counties_df['date'] = pd.to_datetime(counties_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = 40 #for splitting into training and testing data\n",
    "\n",
    "#initialize lists\n",
    "inputs_total = []\n",
    "conditions_total = []\n",
    "\n",
    "train_inputs = []\n",
    "train_targets = []\n",
    "train_conditions = []\n",
    "\n",
    "test_inputs = []\n",
    "test_targets = []\n",
    "test_conditions = []\n",
    "\n",
    "fips = set(np.array(counties_df['fips'])) #list of unique fips\n",
    "\n",
    "dateshift = 35 #so here the first 35 days are like all 0 so i shifted the data we're interested in back by 35 days\n",
    "daterange = pd.date_range(min(counties_df['date'] + datetime.timedelta(days = dateshift)),\n",
    "                          max(counties_df['date'])).tolist() #range of dates \n",
    "\n",
    "\n",
    "fips_fewcases = [] #store fips of cases that are too few to model\n",
    "fips_manycases = [] #store fips of cases that we are modeling with RNN\n",
    "\n",
    "for i in fips: #iterate through counties \n",
    "    c_df = counties_df[counties_df['fips'] == i] #county specific dataframe\n",
    "        \n",
    "    if max(c_df['deaths']) <= 2: #don't do anything if there are too few cases \n",
    "        fips_fewcases.append(i)\n",
    "    \n",
    "    elif max(c_df['deaths']) > 2:\n",
    "        \n",
    "        x1 = np.zeros(len(daterange)) #x1 stores cases\n",
    "        x2 = np.zeros(len(daterange)) #x2 stores deaths\n",
    "\n",
    "        c_daterange = c_df['date'].tolist() #daterange for this specific counties\n",
    "\n",
    "        for j in range(len(daterange)): #populating time series data for each county  \n",
    "            if daterange[j] in c_daterange: #if there is data for the county for this date, populate x1 and x2\n",
    "                x1[j] = c_df[c_df['date'] == daterange[j]]['cases'].values[0]\n",
    "                x2[j] = c_df[c_df['date'] == daterange[j]]['deaths'].values[0]\n",
    "        \n",
    "        # compute moving averages of cases and deaths data over 5 days\n",
    "        x3 = moving_avg_np_array(x1, 5)\n",
    "        x4 = moving_avg_np_array(x2, 5)\n",
    "\n",
    "        days = np.arange(0, len(x1)) #range of days... to indicate progression of disease?\n",
    "        \n",
    "        plt.plot(days, x4) #plot moving avg deaths\n",
    "        \n",
    "        x = np.stack((piecewise_log(x1), piecewise_log(x2), days), axis = 1) #construct input data\n",
    "        \n",
    "        x_train = x[:split_point] #split into training and testing\n",
    "        x_test = x[split_point:]\n",
    "        \n",
    "        inputs_total.append(x)\n",
    "        \n",
    "        #construct conditions... one hot encoded states\n",
    "        p = counties_df[counties_df['fips'] == i]['states_encoded'].values[0]\n",
    "        conditions_total.append(np.array(p))\n",
    "        \n",
    "        #break up into little batch thingies\n",
    "        data_gen_train = TimeseriesGenerator(x_train, x_train,\n",
    "                                       length=10, sampling_rate=1,\n",
    "                                       batch_size=2)\n",
    "        \n",
    "        data_gen_test = TimeseriesGenerator(x_test, x_test,\n",
    "                                       length=10, sampling_rate=1,\n",
    "                                       batch_size=2)\n",
    "\n",
    "        #construct training data\n",
    "        for k in range(len(data_gen_train)):\n",
    "            x_b, y_b = data_gen_train[k]\n",
    "            \n",
    "            for l in range(len(x_b)):\n",
    "\n",
    "                x_batch = x_b[l]\n",
    "                y_batch = y_b[l]\n",
    "                \n",
    "                train_inputs.append(x_batch)\n",
    "                train_targets.append(y_batch)\n",
    "\n",
    "                #conditions   \n",
    "                train_conditions.append(np.array(p))\n",
    "        \n",
    "        #construct test data\n",
    "        for k in range(len(data_gen_test)):\n",
    "            x_b, y_b = data_gen_test[k]\n",
    "            \n",
    "            for l in range(len(x_b)):\n",
    "\n",
    "                x_batch = x_b[l]\n",
    "                y_batch = y_b[l]\n",
    "                \n",
    "                test_inputs.append(x_batch)\n",
    "                test_targets.append(y_batch)\n",
    "\n",
    "                #conditions   \n",
    "                test_conditions.append(np.array(p))\n",
    "\n",
    "plt.title('Moving Average Deaths over time in each county')      \n",
    "plt.figure()\n",
    "                \n",
    "#make things into arrays\n",
    "test_inputs = np.array(test_inputs)\n",
    "test_targets = np.array(test_targets)\n",
    "test_conditions = np.array(test_conditions)\n",
    "\n",
    "train_inputs = np.array(train_inputs)\n",
    "train_targets = np.array(train_targets)\n",
    "train_conditions = np.array(train_conditions)\n",
    "\n",
    "inputs_total = np.array(inputs_total)\n",
    "conditions_total = np.array(conditions_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
